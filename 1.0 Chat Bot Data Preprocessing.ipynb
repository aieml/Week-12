{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dataset=json.load(open('conversation.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=dataset['conversations']\n",
    "\n",
    "data=[]\n",
    "target=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the conversations in the .jason file into data and target\n",
    "for i in range(len(conv)):\n",
    "    for j in range(len(conv[i])):\n",
    "        if j<len(conv[i])-1:\n",
    "            data.append(conv[i][j])\n",
    "            target.append(conv[i][j+1])           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Good', 'morning', ',', 'how', 'are', 'you', '?'], ['I', 'am', 'doing', 'well', ',', 'how', 'about', 'you', '?'], ['I', \"'m\", 'also', 'good', '.'], ['That', \"'s\", 'good', 'to', 'hear', '.'], ['Hello'], ['Hi'], ['How', 'are', 'you', 'doing', '?'], ['I', 'am', 'doing', 'well', '.'], ['That', 'is', 'good', 'to', 'hear'], ['Yes', 'it', 'is', '.'], ['Can', 'I', 'help', 'you', 'with', 'anything', '?'], ['Yes', ',', 'I', 'have', 'a', 'question', '.'], ['What', 'is', 'your', 'question', '?'], ['Could', 'I', 'borrow', 'a', 'cup', 'of', 'sugar', '?'], ['I', \"'m\", 'sorry', ',', 'but', 'I', 'do', \"n't\", 'have', 'any', '.'], ['Thank', 'you', 'anyway'], ['How', 'are', 'you', 'doing', '?'], ['I', 'am', 'doing', 'well', ',', 'how', 'about', 'you', '?'], ['I', 'am', 'also', 'good', '.'], ['Have', 'you', 'heard', 'the', 'news', '?'], ['What', 'is', 'your', 'favorite', 'book', '?'], ['I', 'ca', \"n't\", 'read', '.'], ['So', 'what', \"'s\", 'your', 'favorite', 'color', '?'], ['Who', 'are', 'you', '?'], ['Who', '?', 'Who', 'is', 'but', 'a', 'form', 'following', 'the', 'function', 'of', 'what'], ['What', 'are', 'you', 'then', '?'], ['A', 'man', 'in', 'a', 'mask', '.'], ['I', 'can', 'see', 'that', '.'], ['It', \"'s\", 'not', 'your', 'powers', 'of', 'observation', 'I', 'doubt', ',', 'but', 'merely', 'the', 'paradoxical', 'nature', 'of', 'asking', 'a', 'masked', 'man', 'who', 'is', '.', 'But', 'tell', 'me', ',', 'do', 'you', 'like', 'music', '?'], ['I', 'like', 'seeing', 'movies', '.'], ['What', 'kind', 'of', 'movies', 'do', 'you', 'like', '?'], ['Alice', 'in', 'Wonderland'], ['I', 'wish', 'I', 'was', 'The', 'Mad', 'Hatter', '.'], ['I', 'am', 'working', 'on', 'a', 'project'], ['What', 'are', 'you', 'working', 'on', '?'], ['The', 'cake', 'is', 'a', 'lie', '.'], ['No', 'it', 'is', 'not', '.', 'The', 'cake', 'is', 'delicious', '.'], ['What', 'else', 'is', 'delicious', '?'], ['Nothing'], ['Or', 'something'], ['Tell', 'me', 'about', 'your', 'self', '.'], ['What', 'do', 'you', 'want', 'to', 'know', '?'], ['Are', 'you', 'a', 'robot', '?'], ['Yes', 'I', 'am', '.'], ['What', 'is', 'it', 'like', '?'], ['What', 'is', 'it', 'that', 'you', 'want', 'to', 'know', '?'], ['How', 'do', 'you', 'work', '?'], ['Its', 'complicated', '.'], ['Complex', 'is', 'better', 'than', 'complicated', '.'], ['Simple', 'is', 'better', 'than', 'complex', '.'], ['In', 'the', 'face', 'of', 'ambiguity', ',', 'refuse', 'the', 'temptation', 'to', 'guess', '.'], ['It', 'seems', 'your', 'familiar', 'with', 'the', 'Zen', 'of', 'Python'], ['I', 'am', '.'], ['Do', 'you', 'know', 'all', 'of', 'it', '?'], ['Beautiful', 'is', 'better', 'than', 'ugly', '.'], ['Explicit', 'is', 'better', 'than', 'implicit', '.'], ['Simple', 'is', 'better', 'than', 'complex', '.'], ['Complex', 'is', 'better', 'than', 'complicated', '.'], ['Flat', 'is', 'better', 'than', 'nested', '.'], ['Sparse', 'is', 'better', 'than', 'dense', '.'], ['Readability', 'counts', '.'], ['Special', 'cases', 'are', \"n't\", 'special', 'enough', 'to', 'break', 'the', 'rules', '.'], ['Although', 'practicality', 'beats', 'purity', '.'], ['Errors', 'should', 'never', 'pass', 'silently', '.'], ['Unless', 'explicitly', 'silenced', '.'], ['In', 'the', 'face', 'of', 'ambiguity', ',', 'refuse', 'the', 'temptation', 'to', 'guess', '.'], ['There', 'should', 'be', 'one', '--', 'and', 'preferably', 'only', 'one', '--', 'obvious', 'way', 'to', 'do', 'it', '.'], ['Although', 'that', 'way', 'may', 'not', 'be', 'obvious', 'at', 'first', 'unless', 'you', \"'re\", 'Dutch', '.'], ['Now', 'is', 'better', 'than', 'never', '.'], ['Although', 'never', 'is', 'often', 'better', 'than', 'right', 'now', '.'], ['If', 'the', 'implementation', 'is', 'hard', 'to', 'explain', ',', 'it', \"'s\", 'a', 'bad', 'idea', '.'], ['If', 'the', 'implementation', 'is', 'easy', 'to', 'explain', ',', 'it', 'may', 'be', 'a', 'good', 'idea', '.'], ['Namespaces', 'are', 'one', 'honking', 'great', 'idea', '.', 'Let', \"'s\", 'do', 'more', 'of', 'those', '!'], ['Are', 'you', 'a', 'programmer', '?'], ['I', 'am', 'a', 'programmer'], ['What', 'languages', 'do', 'you', 'like', 'to', 'use', '?'], ['I', 'use', 'Python', ',', 'Java', 'and', 'C++', 'quite', 'often', '.'], ['I', 'use', 'Python', 'quite', 'a', 'bit', 'myself', '.'], ['I', \"'m\", 'not', 'incredibly', 'fond', 'of', 'Java', '.'], ['What', 'annoys', 'you', '?'], ['What', 'does', 'YOLO', 'mean', '?'], ['It', 'means', 'you', 'only', 'live', 'once', '.', 'Where', 'did', 'you', 'hear', 'that', '?'], ['Did', 'I', 'ever', 'live', '?'], ['It', 'depends', 'how', 'you', 'define', 'life'], ['Life', 'is', 'the', 'condition', 'that', 'distinguishes', 'organisms', 'from', 'inorganic', 'matter', ',', 'including', 'the', 'capacity', 'for', 'growth', ',', 'reproduction', ',', 'functional', 'activity', ',', 'and', 'continual', 'change', 'preceding', 'death', '.'], ['Can', 'I', 'ask', 'you', 'a', 'question', '?']]\n"
     ]
    }
   ],
   "source": [
    "#tokenzing the sentences\n",
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "\n",
    "data_tok=[nltk.word_tokenize(dialog) for dialog in data]\n",
    "target_tok=[nltk.word_tokenize(dialog) for dialog in target]\n",
    "\n",
    "print(data_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:smart_open.smart_open_lib:this function is deprecated, use smart_open.open instead\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "model=models.Word2Vec.load('H:/word2vec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the tokenized arrays into vectors\n",
    "data_vec=[]\n",
    "target_vec=[]\n",
    "\n",
    "for sentence in data_tok:\n",
    "    sentence_vector=[model[word] for word in sentence if word in model.vocab]\n",
    "    data_vec.append(sentence_vector)\n",
    "\n",
    "for sentence in target_tok:\n",
    "    sentence_vector=[model[word] for word in sentence if word in model.vocab]\n",
    "    target_vec.append(sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Limiting the size of the each sentence vector to be 15\n",
    "import numpy as np\n",
    "\n",
    "sentence_end=np.ones((300L,),dtype=np.float32)\n",
    "\n",
    "for vector in data_vec:\n",
    "    \n",
    "    vector[14:]=[]   #limitting the words in a sentence to 15\n",
    "    vector.append(sentence_end) \n",
    "\n",
    "for vector in data_vec:\n",
    "    if(len(vector)<15):\n",
    "        for i in range(15-len(vector)):\n",
    "            vector.append(sentence_end) #filling the empty words from vector of ones\n",
    "    \n",
    "\n",
    "for vector in target_vec:\n",
    "    \n",
    "    vector[14:]=[]   #limitting the words in a sentence to 15\n",
    "    vector.append(sentence_end) \n",
    "\n",
    "for vector in target_vec:\n",
    "    if(len(vector)<15):\n",
    "        for i in range(15-len(vector)):\n",
    "            vector.append(sentence_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 300)\n"
     ]
    }
   ],
   "source": [
    "#implementing the Neural Network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM,SimpleRNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_vec=np.array(data_vec)\n",
    "target_vec=np.array(target_vec)\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(data_vec,target_vec,test_size=0.1)\n",
    "\n",
    "print(train_data.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(15, 300), return_sequences=True, activation=\"sigmoid\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\")`\n",
      "  \"\"\"\n",
      "J:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(15, 300), return_sequences=True, activation=\"sigmoid\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\")`\n",
      "  \n",
      "J:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(15, 300), return_sequences=True, activation=\"sigmoid\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\")`\n",
      "  import sys\n",
      "J:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(15, 300), return_sequences=True, activation=\"sigmoid\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Neural Network Model\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(LSTM(output_dim=300,input_shape=train_data.shape[1:],return_sequences=True,init='glorot_normal',inner_init='glorot_normal',activation='sigmoid'))\n",
    "model.add(LSTM(output_dim=300,input_shape=train_data.shape[1:],return_sequences=True,init='glorot_normal',inner_init='glorot_normal',activation='sigmoid'))\n",
    "model.add(LSTM(output_dim=300,input_shape=train_data.shape[1:],return_sequences=True,init='glorot_normal',inner_init='glorot_normal',activation='sigmoid'))\n",
    "model.add(LSTM(output_dim=300,input_shape=train_data.shape[1:],return_sequences=True,init='glorot_normal',inner_init='glorot_normal',activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='cosine_proximity',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "86/86 [==============================] - 8s 95ms/step - loss: -0.6327 - acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.6475 - acc: 0.0124\n",
      "Epoch 3/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.6528 - acc: 0.0209\n",
      "Epoch 4/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.6573 - acc: 0.0209\n",
      "Epoch 5/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.6616 - acc: 0.0217\n",
      "Epoch 6/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.6651 - acc: 0.0194\n",
      "Epoch 7/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.6689 - acc: 0.0039\n",
      "Epoch 8/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.6724 - acc: 0.0039\n",
      "Epoch 9/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.6762 - acc: 0.0178\n",
      "Epoch 10/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.6812 - acc: 0.0248\n",
      "Epoch 11/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.6878 - acc: 0.0248\n",
      "Epoch 12/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.6960 - acc: 0.0194\n",
      "Epoch 13/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7044 - acc: 0.0085\n",
      "Epoch 14/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7094 - acc: 0.0194\n",
      "Epoch 15/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7150 - acc: 0.0233\n",
      "Epoch 16/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7189 - acc: 0.0147\n",
      "Epoch 17/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7198 - acc: 0.0132\n",
      "Epoch 18/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7218 - acc: 0.0101\n",
      "Epoch 19/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7221 - acc: 0.0078\n",
      "Epoch 20/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7238 - acc: 0.0047\n",
      "Epoch 21/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7236 - acc: 0.0039\n",
      "Epoch 22/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7250 - acc: 0.0039\n",
      "Epoch 23/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7246 - acc: 0.0039\n",
      "Epoch 24/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7252 - acc: 0.0039\n",
      "Epoch 25/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7258 - acc: 0.0031\n",
      "Epoch 26/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7255 - acc: 0.0116\n",
      "Epoch 27/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7257 - acc: 0.0140\n",
      "Epoch 28/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7272 - acc: 0.0202\n",
      "Epoch 29/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7230 - acc: 0.0147\n",
      "Epoch 30/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7273 - acc: 0.0163\n",
      "Epoch 31/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7245 - acc: 0.0155\n",
      "Epoch 32/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7252 - acc: 0.0147\n",
      "Epoch 33/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7267 - acc: 0.0163\n",
      "Epoch 34/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7271 - acc: 0.0171\n",
      "Epoch 35/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7274 - acc: 0.0171\n",
      "Epoch 36/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7281 - acc: 0.0186\n",
      "Epoch 37/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7289 - acc: 0.0248\n",
      "Epoch 38/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7290 - acc: 0.0233\n",
      "Epoch 39/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7282 - acc: 0.0233\n",
      "Epoch 40/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7298 - acc: 0.0209\n",
      "Epoch 41/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7289 - acc: 0.0209\n",
      "Epoch 42/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7293 - acc: 0.0202\n",
      "Epoch 43/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7291 - acc: 0.0248\n",
      "Epoch 44/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7306 - acc: 0.0178\n",
      "Epoch 45/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7308 - acc: 0.0194\n",
      "Epoch 46/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7311 - acc: 0.0209\n",
      "Epoch 47/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7309 - acc: 0.0171\n",
      "Epoch 48/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7320 - acc: 0.0171\n",
      "Epoch 49/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7317 - acc: 0.0171\n",
      "Epoch 50/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7326 - acc: 0.0171\n",
      "Epoch 51/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7327 - acc: 0.0163\n",
      "Epoch 52/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7333 - acc: 0.0163\n",
      "Epoch 53/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7329 - acc: 0.0171\n",
      "Epoch 54/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7340 - acc: 0.0163\n",
      "Epoch 55/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7345 - acc: 0.0155\n",
      "Epoch 56/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7340 - acc: 0.0163\n",
      "Epoch 57/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7323 - acc: 0.0171\n",
      "Epoch 58/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7342 - acc: 0.0155\n",
      "Epoch 59/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7378 - acc: 0.0178\n",
      "Epoch 60/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7346 - acc: 0.0186\n",
      "Epoch 61/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7363 - acc: 0.0155\n",
      "Epoch 62/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7338 - acc: 0.0194\n",
      "Epoch 63/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7388 - acc: 0.0163\n",
      "Epoch 64/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7393 - acc: 0.0194\n",
      "Epoch 65/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7375 - acc: 0.0217\n",
      "Epoch 66/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7365 - acc: 0.0147\n",
      "Epoch 67/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7372 - acc: 0.0171\n",
      "Epoch 68/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7376 - acc: 0.0194\n",
      "Epoch 69/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7386 - acc: 0.0186\n",
      "Epoch 70/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7391 - acc: 0.0225\n",
      "Epoch 71/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7394 - acc: 0.0147\n",
      "Epoch 72/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7392 - acc: 0.0194\n",
      "Epoch 73/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7423 - acc: 0.0217\n",
      "Epoch 74/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7412 - acc: 0.0209\n",
      "Epoch 75/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7423 - acc: 0.0240\n",
      "Epoch 76/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7439 - acc: 0.0202\n",
      "Epoch 77/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7443 - acc: 0.0194\n",
      "Epoch 78/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7418 - acc: 0.0202\n",
      "Epoch 79/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7436 - acc: 0.0240\n",
      "Epoch 80/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7448 - acc: 0.0248\n",
      "Epoch 81/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7459 - acc: 0.0202\n",
      "Epoch 82/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7465 - acc: 0.0225\n",
      "Epoch 83/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7468 - acc: 0.0171\n",
      "Epoch 84/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7478 - acc: 0.0178\n",
      "Epoch 85/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7488 - acc: 0.0202\n",
      "Epoch 86/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7476 - acc: 0.0209\n",
      "Epoch 87/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7495 - acc: 0.0194\n",
      "Epoch 88/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7485 - acc: 0.0124\n",
      "Epoch 89/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7483 - acc: 0.0163\n",
      "Epoch 90/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7503 - acc: 0.0178\n",
      "Epoch 91/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7499 - acc: 0.0186\n",
      "Epoch 92/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7497 - acc: 0.0225\n",
      "Epoch 93/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7507 - acc: 0.0209\n",
      "Epoch 94/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7490 - acc: 0.0202\n",
      "Epoch 95/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7498 - acc: 0.0209\n",
      "Epoch 96/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7508 - acc: 0.0248\n",
      "Epoch 97/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7525 - acc: 0.0240\n",
      "Epoch 98/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7528 - acc: 0.0264\n",
      "Epoch 99/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7524 - acc: 0.0264\n",
      "Epoch 100/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7501 - acc: 0.0279\n",
      "Epoch 101/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7524 - acc: 0.0264\n",
      "Epoch 102/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7533 - acc: 0.0271\n",
      "Epoch 103/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7530 - acc: 0.0264\n",
      "Epoch 104/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7523 - acc: 0.0240\n",
      "Epoch 105/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7527 - acc: 0.0271\n",
      "Epoch 106/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7539 - acc: 0.0271\n",
      "Epoch 107/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7523 - acc: 0.0271\n",
      "Epoch 108/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7514 - acc: 0.0248\n",
      "Epoch 109/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7511 - acc: 0.0233\n",
      "Epoch 110/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7525 - acc: 0.0302\n",
      "Epoch 111/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7546 - acc: 0.0264\n",
      "Epoch 112/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7545 - acc: 0.0248\n",
      "Epoch 113/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7562 - acc: 0.0264\n",
      "Epoch 114/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7561 - acc: 0.0248\n",
      "Epoch 115/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7557 - acc: 0.0271\n",
      "Epoch 116/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7562 - acc: 0.0264\n",
      "Epoch 117/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7559 - acc: 0.0279\n",
      "Epoch 118/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7542 - acc: 0.0271\n",
      "Epoch 119/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7579 - acc: 0.0264\n",
      "Epoch 120/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7580 - acc: 0.0271\n",
      "Epoch 121/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7573 - acc: 0.0256\n",
      "Epoch 122/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7577 - acc: 0.0264\n",
      "Epoch 123/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7589 - acc: 0.0271\n",
      "Epoch 124/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7572 - acc: 0.0271\n",
      "Epoch 125/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7582 - acc: 0.0279\n",
      "Epoch 126/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7547 - acc: 0.0248\n",
      "Epoch 127/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7550 - acc: 0.0264\n",
      "Epoch 128/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7550 - acc: 0.0279\n",
      "Epoch 129/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7554 - acc: 0.0264\n",
      "Epoch 130/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7531 - acc: 0.0264\n",
      "Epoch 131/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7547 - acc: 0.0264\n",
      "Epoch 132/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7525 - acc: 0.0279\n",
      "Epoch 133/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7573 - acc: 0.0279\n",
      "Epoch 134/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7588 - acc: 0.0264\n",
      "Epoch 135/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7590 - acc: 0.0264\n",
      "Epoch 136/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7582 - acc: 0.0256\n",
      "Epoch 137/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7569 - acc: 0.0264\n",
      "Epoch 138/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7572 - acc: 0.0256\n",
      "Epoch 139/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7574 - acc: 0.0248\n",
      "Epoch 140/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7566 - acc: 0.0271\n",
      "Epoch 141/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7529 - acc: 0.0279\n",
      "Epoch 142/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7494 - acc: 0.0279\n",
      "Epoch 143/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7570 - acc: 0.0287\n",
      "Epoch 144/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7592 - acc: 0.0256\n",
      "Epoch 145/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7563 - acc: 0.0240\n",
      "Epoch 146/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7574 - acc: 0.0256\n",
      "Epoch 147/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7569 - acc: 0.0264\n",
      "Epoch 148/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7541 - acc: 0.0287\n",
      "Epoch 149/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7556 - acc: 0.0318\n",
      "Epoch 150/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7584 - acc: 0.0271\n",
      "Epoch 151/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7598 - acc: 0.0287\n",
      "Epoch 152/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7593 - acc: 0.0264\n",
      "Epoch 153/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7590 - acc: 0.0279\n",
      "Epoch 154/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7611 - acc: 0.0279\n",
      "Epoch 155/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7616 - acc: 0.0271\n",
      "Epoch 156/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7613 - acc: 0.0287\n",
      "Epoch 157/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7626 - acc: 0.0264\n",
      "Epoch 158/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7621 - acc: 0.0287\n",
      "Epoch 159/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7622 - acc: 0.0271\n",
      "Epoch 160/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7617 - acc: 0.0287\n",
      "Epoch 161/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7606 - acc: 0.0310\n",
      "Epoch 162/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7611 - acc: 0.0295\n",
      "Epoch 163/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7614 - acc: 0.0279\n",
      "Epoch 164/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7618 - acc: 0.0256\n",
      "Epoch 165/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7598 - acc: 0.0279\n",
      "Epoch 166/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7608 - acc: 0.0295\n",
      "Epoch 167/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7606 - acc: 0.0295\n",
      "Epoch 168/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7636 - acc: 0.0287\n",
      "Epoch 169/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7621 - acc: 0.0295\n",
      "Epoch 170/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7632 - acc: 0.0256\n",
      "Epoch 171/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7641 - acc: 0.0248\n",
      "Epoch 172/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7640 - acc: 0.0264\n",
      "Epoch 173/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7647 - acc: 0.0264\n",
      "Epoch 174/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7639 - acc: 0.0287\n",
      "Epoch 175/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7617 - acc: 0.0295\n",
      "Epoch 176/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7621 - acc: 0.0310\n",
      "Epoch 177/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7597 - acc: 0.0264\n",
      "Epoch 178/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7605 - acc: 0.0256\n",
      "Epoch 179/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7612 - acc: 0.0264\n",
      "Epoch 180/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7609 - acc: 0.0256\n",
      "Epoch 181/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7637 - acc: 0.0264\n",
      "Epoch 182/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7631 - acc: 0.0256\n",
      "Epoch 183/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7620 - acc: 0.0302\n",
      "Epoch 184/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7610 - acc: 0.0341\n",
      "Epoch 185/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7603 - acc: 0.0310\n",
      "Epoch 186/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7608 - acc: 0.0271\n",
      "Epoch 187/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7580 - acc: 0.0256\n",
      "Epoch 188/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7614 - acc: 0.0271\n",
      "Epoch 189/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7622 - acc: 0.0256\n",
      "Epoch 190/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7641 - acc: 0.0318\n",
      "Epoch 191/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7634 - acc: 0.0279\n",
      "Epoch 192/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7630 - acc: 0.0302\n",
      "Epoch 193/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7631 - acc: 0.0256\n",
      "Epoch 194/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7646 - acc: 0.0256\n",
      "Epoch 195/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7650 - acc: 0.0248\n",
      "Epoch 196/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7653 - acc: 0.0248\n",
      "Epoch 197/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7647 - acc: 0.0264\n",
      "Epoch 198/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7649 - acc: 0.0295\n",
      "Epoch 199/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7669 - acc: 0.0295\n",
      "Epoch 200/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7660 - acc: 0.0318\n",
      "Epoch 201/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7669 - acc: 0.0271\n",
      "Epoch 202/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7650 - acc: 0.0279\n",
      "Epoch 203/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7633 - acc: 0.0271\n",
      "Epoch 204/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7645 - acc: 0.0310\n",
      "Epoch 205/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7636 - acc: 0.0302\n",
      "Epoch 206/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7652 - acc: 0.0295\n",
      "Epoch 207/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7660 - acc: 0.0302\n",
      "Epoch 208/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7654 - acc: 0.0302\n",
      "Epoch 209/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7619 - acc: 0.0884\n",
      "Epoch 210/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7649 - acc: 0.0264\n",
      "Epoch 211/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7640 - acc: 0.0287\n",
      "Epoch 212/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7661 - acc: 0.0256\n",
      "Epoch 213/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7657 - acc: 0.0279\n",
      "Epoch 214/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7658 - acc: 0.0287\n",
      "Epoch 215/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7654 - acc: 0.0302\n",
      "Epoch 216/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7644 - acc: 0.0271\n",
      "Epoch 217/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7666 - acc: 0.0240\n",
      "Epoch 218/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7657 - acc: 0.0271\n",
      "Epoch 219/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7650 - acc: 0.0248\n",
      "Epoch 220/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7638 - acc: 0.0302\n",
      "Epoch 221/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7649 - acc: 0.0287\n",
      "Epoch 222/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7646 - acc: 0.0341\n",
      "Epoch 223/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7649 - acc: 0.0326\n",
      "Epoch 224/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7665 - acc: 0.0295\n",
      "Epoch 225/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7661 - acc: 0.0310\n",
      "Epoch 226/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7669 - acc: 0.0279\n",
      "Epoch 227/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7658 - acc: 0.0302\n",
      "Epoch 228/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7685 - acc: 0.0310\n",
      "Epoch 229/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7675 - acc: 0.0287\n",
      "Epoch 230/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7697 - acc: 0.0264\n",
      "Epoch 231/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7695 - acc: 0.0271\n",
      "Epoch 232/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7704 - acc: 0.0264\n",
      "Epoch 233/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7656 - acc: 0.0279\n",
      "Epoch 234/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7660 - acc: 0.0287\n",
      "Epoch 235/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7641 - acc: 0.0364\n",
      "Epoch 236/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7638 - acc: 0.0271\n",
      "Epoch 237/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7603 - acc: 0.0388\n",
      "Epoch 238/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7634 - acc: 0.0240\n",
      "Epoch 239/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7636 - acc: 0.0326\n",
      "Epoch 240/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7644 - acc: 0.0302\n",
      "Epoch 241/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7638 - acc: 0.0395\n",
      "Epoch 242/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7642 - acc: 0.0287\n",
      "Epoch 243/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7658 - acc: 0.0364\n",
      "Epoch 244/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7672 - acc: 0.0287\n",
      "Epoch 245/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7680 - acc: 0.0264\n",
      "Epoch 246/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7696 - acc: 0.0310\n",
      "Epoch 247/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7710 - acc: 0.0287\n",
      "Epoch 248/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7708 - acc: 0.0310\n",
      "Epoch 249/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7696 - acc: 0.0279\n",
      "Epoch 250/500\n",
      "86/86 [==============================] - 2s 19ms/step - loss: -0.7702 - acc: 0.0256\n",
      "Epoch 251/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7698 - acc: 0.0302\n",
      "Epoch 252/500\n",
      "86/86 [==============================] - 2s 20ms/step - loss: -0.7703 - acc: 0.0264\n",
      "Epoch 253/500\n",
      "86/86 [==============================] - 2s 19ms/step - loss: -0.7713 - acc: 0.0295\n",
      "Epoch 254/500\n",
      "86/86 [==============================] - 2s 19ms/step - loss: -0.7719 - acc: 0.0302\n",
      "Epoch 255/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7715 - acc: 0.0326\n",
      "Epoch 256/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7718 - acc: 0.0295\n",
      "Epoch 257/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7709 - acc: 0.0357\n",
      "Epoch 258/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7713 - acc: 0.0318\n",
      "Epoch 259/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7708 - acc: 0.0326\n",
      "Epoch 260/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7703 - acc: 0.0295\n",
      "Epoch 261/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7712 - acc: 0.0310\n",
      "Epoch 262/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7702 - acc: 0.0349\n",
      "Epoch 263/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7717 - acc: 0.0295\n",
      "Epoch 264/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7699 - acc: 0.0333\n",
      "Epoch 265/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7697 - acc: 0.0333\n",
      "Epoch 266/500\n",
      "86/86 [==============================] - 3s 30ms/step - loss: -0.7688 - acc: 0.0302\n",
      "Epoch 267/500\n",
      "86/86 [==============================] - 3s 30ms/step - loss: -0.7719 - acc: 0.0295\n",
      "Epoch 268/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7702 - acc: 0.0333\n",
      "Epoch 269/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7666 - acc: 0.0295\n",
      "Epoch 270/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7697 - acc: 0.0333\n",
      "Epoch 271/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7697 - acc: 0.0357\n",
      "Epoch 272/500\n",
      "86/86 [==============================] - 2s 20ms/step - loss: -0.7701 - acc: 0.0295\n",
      "Epoch 273/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7705 - acc: 0.0287\n",
      "Epoch 274/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7696 - acc: 0.0395\n",
      "Epoch 275/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7699 - acc: 0.0318\n",
      "Epoch 276/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7705 - acc: 0.0287\n",
      "Epoch 277/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7669 - acc: 0.0364\n",
      "Epoch 278/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7643 - acc: 0.0302\n",
      "Epoch 279/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7644 - acc: 0.0364\n",
      "Epoch 280/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7684 - acc: 0.0318\n",
      "Epoch 281/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7665 - acc: 0.0380\n",
      "Epoch 282/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7688 - acc: 0.0279\n",
      "Epoch 283/500\n",
      "86/86 [==============================] - 2s 19ms/step - loss: -0.7701 - acc: 0.0318\n",
      "Epoch 284/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7698 - acc: 0.0318\n",
      "Epoch 285/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7712 - acc: 0.0380\n",
      "Epoch 286/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7701 - acc: 0.0310\n",
      "Epoch 287/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7724 - acc: 0.0302\n",
      "Epoch 288/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7721 - acc: 0.0349\n",
      "Epoch 289/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7733 - acc: 0.0341\n",
      "Epoch 290/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7734 - acc: 0.0333\n",
      "Epoch 291/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7734 - acc: 0.0372\n",
      "Epoch 292/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7719 - acc: 0.0310\n",
      "Epoch 293/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7673 - acc: 0.0326\n",
      "Epoch 294/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7698 - acc: 0.0302\n",
      "Epoch 295/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7733 - acc: 0.0295\n",
      "Epoch 296/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7735 - acc: 0.0295\n",
      "Epoch 297/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7746 - acc: 0.0357\n",
      "Epoch 298/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7729 - acc: 0.0349\n",
      "Epoch 299/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7742 - acc: 0.0310\n",
      "Epoch 300/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7717 - acc: 0.0349\n",
      "Epoch 301/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7723 - acc: 0.0341\n",
      "Epoch 302/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7712 - acc: 0.0310\n",
      "Epoch 303/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7743 - acc: 0.0372\n",
      "Epoch 304/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7724 - acc: 0.0326\n",
      "Epoch 305/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7741 - acc: 0.0341\n",
      "Epoch 306/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7742 - acc: 0.0364\n",
      "Epoch 307/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7715 - acc: 0.0333\n",
      "Epoch 308/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7731 - acc: 0.0279\n",
      "Epoch 309/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7744 - acc: 0.0357\n",
      "Epoch 310/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7728 - acc: 0.0349\n",
      "Epoch 311/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7729 - acc: 0.0326\n",
      "Epoch 312/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7715 - acc: 0.0341\n",
      "Epoch 313/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7726 - acc: 0.0372\n",
      "Epoch 314/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7698 - acc: 0.0357\n",
      "Epoch 315/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7720 - acc: 0.0318\n",
      "Epoch 316/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7746 - acc: 0.0364\n",
      "Epoch 317/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7753 - acc: 0.0333\n",
      "Epoch 318/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7754 - acc: 0.0341\n",
      "Epoch 319/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7746 - acc: 0.0372\n",
      "Epoch 320/500\n",
      "86/86 [==============================] - 2s 20ms/step - loss: -0.7752 - acc: 0.0333\n",
      "Epoch 321/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7705 - acc: 0.0349\n",
      "Epoch 322/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7735 - acc: 0.0403\n",
      "Epoch 323/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7747 - acc: 0.0326\n",
      "Epoch 324/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7730 - acc: 0.0388\n",
      "Epoch 325/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7733 - acc: 0.0364\n",
      "Epoch 326/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7736 - acc: 0.0341\n",
      "Epoch 327/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7746 - acc: 0.0380\n",
      "Epoch 328/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7731 - acc: 0.0341\n",
      "Epoch 329/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7725 - acc: 0.0357\n",
      "Epoch 330/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7720 - acc: 0.0395\n",
      "Epoch 331/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7664 - acc: 0.0372\n",
      "Epoch 332/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7744 - acc: 0.0411\n",
      "Epoch 333/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7732 - acc: 0.0372\n",
      "Epoch 334/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7751 - acc: 0.0364\n",
      "Epoch 335/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7737 - acc: 0.0395\n",
      "Epoch 336/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7730 - acc: 0.0426\n",
      "Epoch 337/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7746 - acc: 0.0318\n",
      "Epoch 338/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7749 - acc: 0.0388\n",
      "Epoch 339/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7764 - acc: 0.0326\n",
      "Epoch 340/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7727 - acc: 0.0364\n",
      "Epoch 341/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7747 - acc: 0.0442\n",
      "Epoch 342/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7702 - acc: 0.0310\n",
      "Epoch 343/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7689 - acc: 0.0426\n",
      "Epoch 344/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7661 - acc: 0.0333\n",
      "Epoch 345/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7649 - acc: 0.0388\n",
      "Epoch 346/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7691 - acc: 0.0380\n",
      "Epoch 347/500\n",
      "86/86 [==============================] - 2s 20ms/step - loss: -0.7710 - acc: 0.0388\n",
      "Epoch 348/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7729 - acc: 0.0341\n",
      "Epoch 349/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7737 - acc: 0.0395\n",
      "Epoch 350/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7748 - acc: 0.0349\n",
      "Epoch 351/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7760 - acc: 0.0411\n",
      "Epoch 352/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7757 - acc: 0.0364\n",
      "Epoch 353/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7758 - acc: 0.0419\n",
      "Epoch 354/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7734 - acc: 0.0388\n",
      "Epoch 355/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7729 - acc: 0.0318\n",
      "Epoch 356/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7704 - acc: 0.0380\n",
      "Epoch 357/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7735 - acc: 0.0372\n",
      "Epoch 358/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7751 - acc: 0.0395\n",
      "Epoch 359/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7762 - acc: 0.0333\n",
      "Epoch 360/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7750 - acc: 0.0426\n",
      "Epoch 361/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7774 - acc: 0.0380\n",
      "Epoch 362/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7775 - acc: 0.0426\n",
      "Epoch 363/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7763 - acc: 0.0395\n",
      "Epoch 364/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7767 - acc: 0.0372\n",
      "Epoch 365/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7771 - acc: 0.0403\n",
      "Epoch 366/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7765 - acc: 0.0380\n",
      "Epoch 367/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7758 - acc: 0.0395\n",
      "Epoch 368/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7760 - acc: 0.0481\n",
      "Epoch 369/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7747 - acc: 0.0333\n",
      "Epoch 370/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7737 - acc: 0.0395\n",
      "Epoch 371/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7748 - acc: 0.0357\n",
      "Epoch 372/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7736 - acc: 0.0380\n",
      "Epoch 373/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7721 - acc: 0.0349\n",
      "Epoch 374/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7741 - acc: 0.0357\n",
      "Epoch 375/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7754 - acc: 0.0388\n",
      "Epoch 376/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7769 - acc: 0.0372\n",
      "Epoch 377/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7779 - acc: 0.0419\n",
      "Epoch 378/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7757 - acc: 0.0357\n",
      "Epoch 379/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7755 - acc: 0.0411\n",
      "Epoch 380/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7766 - acc: 0.0380\n",
      "Epoch 381/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7772 - acc: 0.0357\n",
      "Epoch 382/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7785 - acc: 0.0411\n",
      "Epoch 383/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7786 - acc: 0.0380\n",
      "Epoch 384/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7771 - acc: 0.0442\n",
      "Epoch 385/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7759 - acc: 0.0388\n",
      "Epoch 386/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7777 - acc: 0.0388\n",
      "Epoch 387/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7763 - acc: 0.0434\n",
      "Epoch 388/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7750 - acc: 0.0326\n",
      "Epoch 389/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7708 - acc: 0.0388\n",
      "Epoch 390/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7751 - acc: 0.0341\n",
      "Epoch 391/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7740 - acc: 0.0426\n",
      "Epoch 392/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7739 - acc: 0.0411\n",
      "Epoch 393/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7762 - acc: 0.0403\n",
      "Epoch 394/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7774 - acc: 0.0403\n",
      "Epoch 395/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7782 - acc: 0.0388\n",
      "Epoch 396/500\n",
      "86/86 [==============================] - 2s 20ms/step - loss: -0.7787 - acc: 0.0403\n",
      "Epoch 397/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7778 - acc: 0.0380\n",
      "Epoch 398/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7773 - acc: 0.0411\n",
      "Epoch 399/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7789 - acc: 0.0388\n",
      "Epoch 400/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7753 - acc: 0.0403\n",
      "Epoch 401/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7763 - acc: 0.0450\n",
      "Epoch 402/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7780 - acc: 0.0364\n",
      "Epoch 403/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7777 - acc: 0.0457\n",
      "Epoch 404/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7779 - acc: 0.0411\n",
      "Epoch 405/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7766 - acc: 0.0403\n",
      "Epoch 406/500\n",
      "86/86 [==============================] - 2s 29ms/step - loss: -0.7753 - acc: 0.0403\n",
      "Epoch 407/500\n",
      "86/86 [==============================] - 3s 29ms/step - loss: -0.7747 - acc: 0.0341\n",
      "Epoch 408/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7768 - acc: 0.0434\n",
      "Epoch 409/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7757 - acc: 0.0419\n",
      "Epoch 410/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7771 - acc: 0.0589\n",
      "Epoch 411/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7727 - acc: 0.0333\n",
      "Epoch 412/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7703 - acc: 0.0450\n",
      "Epoch 413/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7737 - acc: 0.0333\n",
      "Epoch 414/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7760 - acc: 0.0395\n",
      "Epoch 415/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7773 - acc: 0.0388\n",
      "Epoch 416/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7766 - acc: 0.0434\n",
      "Epoch 417/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7760 - acc: 0.0411\n",
      "Epoch 418/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7789 - acc: 0.0426\n",
      "Epoch 419/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7762 - acc: 0.0364\n",
      "Epoch 420/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7785 - acc: 0.0411\n",
      "Epoch 421/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7762 - acc: 0.0403\n",
      "Epoch 422/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7740 - acc: 0.0426\n",
      "Epoch 423/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7711 - acc: 0.0372\n",
      "Epoch 424/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7739 - acc: 0.0442\n",
      "Epoch 425/500\n",
      "86/86 [==============================] - 2s 20ms/step - loss: -0.7760 - acc: 0.0388\n",
      "Epoch 426/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7764 - acc: 0.0388\n",
      "Epoch 427/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7807 - acc: 0.0434\n",
      "Epoch 428/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7805 - acc: 0.1930\n",
      "Epoch 429/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7811 - acc: 0.0411\n",
      "Epoch 430/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7805 - acc: 0.0411\n",
      "Epoch 431/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7801 - acc: 0.0419\n",
      "Epoch 432/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7795 - acc: 0.0411\n",
      "Epoch 433/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7766 - acc: 0.0442\n",
      "Epoch 434/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7732 - acc: 0.0333\n",
      "Epoch 435/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7729 - acc: 0.0442\n",
      "Epoch 436/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7719 - acc: 0.0341\n",
      "Epoch 437/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7726 - acc: 0.0442\n",
      "Epoch 438/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7742 - acc: 0.0372\n",
      "Epoch 439/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7713 - acc: 0.0434\n",
      "Epoch 440/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7747 - acc: 0.0380\n",
      "Epoch 441/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7770 - acc: 0.0450\n",
      "Epoch 442/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7779 - acc: 0.0457\n",
      "Epoch 443/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7774 - acc: 0.0457\n",
      "Epoch 444/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7769 - acc: 0.0426\n",
      "Epoch 445/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7798 - acc: 0.0426\n",
      "Epoch 446/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7776 - acc: 0.0473\n",
      "Epoch 447/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7793 - acc: 0.0442\n",
      "Epoch 448/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7800 - acc: 0.0434\n",
      "Epoch 449/500\n",
      "86/86 [==============================] - 2s 19ms/step - loss: -0.7810 - acc: 0.0426\n",
      "Epoch 450/500\n",
      "86/86 [==============================] - 2s 19ms/step - loss: -0.7820 - acc: 0.0473\n",
      "Epoch 451/500\n",
      "86/86 [==============================] - 2s 19ms/step - loss: -0.7828 - acc: 0.0450\n",
      "Epoch 452/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7825 - acc: 0.0481\n",
      "Epoch 453/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7840 - acc: 0.0488\n",
      "Epoch 454/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7837 - acc: 0.0450\n",
      "Epoch 455/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7841 - acc: 0.0543\n",
      "Epoch 456/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7828 - acc: 0.0488\n",
      "Epoch 457/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7841 - acc: 0.0457\n",
      "Epoch 458/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7839 - acc: 0.0488\n",
      "Epoch 459/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7831 - acc: 0.1287\n",
      "Epoch 460/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7839 - acc: 0.0465\n",
      "Epoch 461/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7835 - acc: 0.0426\n",
      "Epoch 462/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7838 - acc: 0.0504\n",
      "Epoch 463/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7838 - acc: 0.0512\n",
      "Epoch 464/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7848 - acc: 0.0488\n",
      "Epoch 465/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7838 - acc: 0.0473\n",
      "Epoch 466/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7841 - acc: 0.0512\n",
      "Epoch 467/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7843 - acc: 0.0481\n",
      "Epoch 468/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7826 - acc: 0.0457\n",
      "Epoch 469/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7832 - acc: 0.0558\n",
      "Epoch 470/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7802 - acc: 0.0465\n",
      "Epoch 471/500\n",
      "86/86 [==============================] - 2s 20ms/step - loss: -0.7818 - acc: 0.0535\n",
      "Epoch 472/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7809 - acc: 0.0527\n",
      "Epoch 473/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7811 - acc: 0.0488\n",
      "Epoch 474/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7809 - acc: 0.0488\n",
      "Epoch 475/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7810 - acc: 0.0512\n",
      "Epoch 476/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7813 - acc: 0.0527\n",
      "Epoch 477/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7816 - acc: 0.0760\n",
      "Epoch 478/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7809 - acc: 0.0543\n",
      "Epoch 479/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7784 - acc: 0.0457\n",
      "Epoch 480/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7793 - acc: 0.0488\n",
      "Epoch 481/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7820 - acc: 0.0488\n",
      "Epoch 482/500\n",
      "86/86 [==============================] - 2s 20ms/step - loss: -0.7830 - acc: 0.0558\n",
      "Epoch 483/500\n",
      "86/86 [==============================] - 2s 19ms/step - loss: -0.7839 - acc: 0.0496\n",
      "Epoch 484/500\n",
      "86/86 [==============================] - 2s 19ms/step - loss: -0.7854 - acc: 0.0527\n",
      "Epoch 485/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7852 - acc: 0.0597\n",
      "Epoch 486/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7860 - acc: 0.0504\n",
      "Epoch 487/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7852 - acc: 0.0504\n",
      "Epoch 488/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7847 - acc: 0.0512\n",
      "Epoch 489/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7854 - acc: 0.0543\n",
      "Epoch 490/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7844 - acc: 0.0535\n",
      "Epoch 491/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7827 - acc: 0.0550\n",
      "Epoch 492/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7837 - acc: 0.0558\n",
      "Epoch 493/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7821 - acc: 0.0504\n",
      "Epoch 494/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7858 - acc: 0.0543\n",
      "Epoch 495/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7826 - acc: 0.0566\n",
      "Epoch 496/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7805 - acc: 0.0527\n",
      "Epoch 497/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7821 - acc: 0.0558\n",
      "Epoch 498/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7792 - acc: 0.0481\n",
      "Epoch 499/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7798 - acc: 0.0550\n",
      "Epoch 500/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7803 - acc: 0.0527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a98bae1a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_vec,target_vec,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7835 - acc: 0.0597\n",
      "Epoch 2/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7822 - acc: 0.0512\n",
      "Epoch 3/500\n",
      "86/86 [==============================] - 2s 21ms/step - loss: -0.7832 - acc: 0.0643\n",
      "Epoch 4/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7851 - acc: 0.0558\n",
      "Epoch 5/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7860 - acc: 0.0543\n",
      "Epoch 6/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7848 - acc: 0.0566\n",
      "Epoch 7/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7848 - acc: 0.0527\n",
      "Epoch 8/500\n",
      "86/86 [==============================] - 2s 29ms/step - loss: -0.7862 - acc: 0.0574\n",
      "Epoch 9/500\n",
      "86/86 [==============================] - 3s 32ms/step - loss: -0.7857 - acc: 0.0512\n",
      "Epoch 10/500\n",
      "86/86 [==============================] - 3s 37ms/step - loss: -0.7864 - acc: 0.0558\n",
      "Epoch 11/500\n",
      "86/86 [==============================] - 3s 34ms/step - loss: -0.7856 - acc: 0.0512\n",
      "Epoch 12/500\n",
      "86/86 [==============================] - 3s 32ms/step - loss: -0.7857 - acc: 0.0581\n",
      "Epoch 13/500\n",
      "86/86 [==============================] - 3s 34ms/step - loss: -0.7862 - acc: 0.0589\n",
      "Epoch 14/500\n",
      "86/86 [==============================] - 3s 36ms/step - loss: -0.7839 - acc: 0.0519\n",
      "Epoch 15/500\n",
      "86/86 [==============================] - 3s 39ms/step - loss: -0.7880 - acc: 0.0574\n",
      "Epoch 16/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7871 - acc: 0.0550\n",
      "Epoch 17/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7889 - acc: 0.0628\n",
      "Epoch 18/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7891 - acc: 0.0628\n",
      "Epoch 19/500\n",
      "86/86 [==============================] - 3s 33ms/step - loss: -0.7877 - acc: 0.0605\n",
      "Epoch 20/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7888 - acc: 0.0620\n",
      "Epoch 21/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7897 - acc: 0.0597\n",
      "Epoch 22/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7896 - acc: 0.0612\n",
      "Epoch 23/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7893 - acc: 0.0612\n",
      "Epoch 24/500\n",
      "86/86 [==============================] - 2s 29ms/step - loss: -0.7889 - acc: 0.0589\n",
      "Epoch 25/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7888 - acc: 0.0558\n",
      "Epoch 26/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7886 - acc: 0.0566\n",
      "Epoch 27/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7877 - acc: 0.0597\n",
      "Epoch 28/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7896 - acc: 0.0643\n",
      "Epoch 29/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7850 - acc: 0.0574\n",
      "Epoch 30/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7861 - acc: 0.0636\n",
      "Epoch 31/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7884 - acc: 0.1124\n",
      "Epoch 32/500\n",
      "86/86 [==============================] - 3s 34ms/step - loss: -0.7876 - acc: 0.0605\n",
      "Epoch 33/500\n",
      "86/86 [==============================] - 3s 32ms/step - loss: -0.7859 - acc: 0.0519\n",
      "Epoch 34/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7880 - acc: 0.0574\n",
      "Epoch 35/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7890 - acc: 0.0643\n",
      "Epoch 36/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7890 - acc: 0.0597\n",
      "Epoch 37/500\n",
      "86/86 [==============================] - 3s 31ms/step - loss: -0.7900 - acc: 0.0667\n",
      "Epoch 38/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7909 - acc: 0.0581\n",
      "Epoch 39/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7901 - acc: 0.0612\n",
      "Epoch 40/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7900 - acc: 0.0589\n",
      "Epoch 41/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7912 - acc: 0.0620\n",
      "Epoch 42/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7899 - acc: 0.0643\n",
      "Epoch 43/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7907 - acc: 0.0651\n",
      "Epoch 44/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7894 - acc: 0.0566\n",
      "Epoch 45/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7910 - acc: 0.0628\n",
      "Epoch 46/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7896 - acc: 0.0636\n",
      "Epoch 47/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7906 - acc: 0.0620\n",
      "Epoch 48/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7918 - acc: 0.0620\n",
      "Epoch 49/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7919 - acc: 0.0651\n",
      "Epoch 50/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7916 - acc: 0.0612\n",
      "Epoch 51/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7926 - acc: 0.0605\n",
      "Epoch 52/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7929 - acc: 0.0659\n",
      "Epoch 53/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7933 - acc: 0.0659\n",
      "Epoch 54/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7924 - acc: 0.0736\n",
      "Epoch 55/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7915 - acc: 0.0705\n",
      "Epoch 56/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7938 - acc: 0.0636\n",
      "Epoch 57/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7928 - acc: 0.0612\n",
      "Epoch 58/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7927 - acc: 0.0690\n",
      "Epoch 59/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7908 - acc: 0.0628\n",
      "Epoch 60/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7913 - acc: 0.0636\n",
      "Epoch 61/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7909 - acc: 0.0667\n",
      "Epoch 62/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7909 - acc: 0.0651\n",
      "Epoch 63/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7913 - acc: 0.0721\n",
      "Epoch 64/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7913 - acc: 0.0667\n",
      "Epoch 65/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7908 - acc: 0.0643\n",
      "Epoch 66/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7898 - acc: 0.0643\n",
      "Epoch 67/500\n",
      "86/86 [==============================] - 2s 27ms/step - loss: -0.7915 - acc: 0.0736\n",
      "Epoch 68/500\n",
      "86/86 [==============================] - 2s 28ms/step - loss: -0.7849 - acc: 0.0605\n",
      "Epoch 69/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7843 - acc: 0.0574\n",
      "Epoch 70/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7892 - acc: 0.0651\n",
      "Epoch 71/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7879 - acc: 0.0674\n",
      "Epoch 72/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7897 - acc: 0.0698\n",
      "Epoch 73/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7884 - acc: 0.0674\n",
      "Epoch 74/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7907 - acc: 0.0628\n",
      "Epoch 75/500\n",
      "86/86 [==============================] - 2s 25ms/step - loss: -0.7931 - acc: 0.0729\n",
      "Epoch 76/500\n",
      "86/86 [==============================] - 2s 22ms/step - loss: -0.7942 - acc: 0.0674\n",
      "Epoch 77/500\n",
      "86/86 [==============================] - 2s 23ms/step - loss: -0.7917 - acc: 0.0659\n",
      "Epoch 78/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7922 - acc: 0.0698\n",
      "Epoch 79/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7922 - acc: 0.0713\n",
      "Epoch 80/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7932 - acc: 0.0729\n",
      "Epoch 81/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7927 - acc: 0.0713\n",
      "Epoch 82/500\n",
      "86/86 [==============================] - 2s 26ms/step - loss: -0.7937 - acc: 0.0682\n",
      "Epoch 83/500\n",
      "86/86 [==============================] - 2s 24ms/step - loss: -0.7929 - acc: 0.0690\n",
      "Epoch 84/500\n",
      "32/86 [==========>...................] - ETA: 1s - loss: -0.8083 - acc: 0.0896"
     ]
    }
   ],
   "source": [
    "model.fit(data_vec,target_vec,epochs=500)\n",
    "model.fit(data_vec,target_vec,epochs=500)\n",
    "model.fit(data_vec,target_vec,epochs=500)\n",
    "model.fit(data_vec,target_vec,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('chatbot_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
